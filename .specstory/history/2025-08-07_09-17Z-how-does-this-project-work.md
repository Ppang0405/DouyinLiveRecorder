<!-- Generated by SpecStory -->

# How does this project work (2025-08-07 09:17Z)

_**User**_

how does this project work?

---

_**Assistant**_

I'll analyze this project to understand how it works. Let me start by examining the key files to understand the structure and functionality.

---

Read file: undefined

---

Read file: undefined

---

Read file: undefined

---

Read file: undefined

---

Now let me examine the main.py file to understand the entry point and core functionality:

---

Read file: undefined

---

Read file: undefined

---

Read file: undefined

---

Read file: undefined

---

Let me also check the demo.py and examine more of the core files to understand the architecture:

---

Read file: undefined

---

Read file: undefined

---

Read file: undefined

---

<details>
            <summary>Listed directory undefined ‚Ä¢ **0** results</summary>
        
No results found
</details>

---

Now I have a comprehensive understanding of this project. Let me create a visual diagram to explain how it works:

---

```mermaid
graph TD
    A["User starts main.py"] --> B["Load Configuration"]
    B --> C["config.ini<br/>(Recording settings)"]
    B --> D["URL_config.ini<br/>(Live stream URLs)"]
    
    C --> E["Initialize FFmpeg"]
    D --> F["Parse Live URLs"]
    
    E --> G["Start Monitoring Loop"]
    F --> G
    
    G --> H["For each URL"]
    H --> I["Identify Platform<br/>(Douyin, TikTok, Bilibili, etc.)"]
    
    I --> J["spider.py<br/>Get Live Stream Data"]
    J --> K["Execute Platform-specific<br/>JavaScript Code"]
    K --> L["Extract Stream URL"]
    
    L --> M{"Is Live?"}
    M -->|Yes| N["stream.py<br/>Get Stream URL"]
    M -->|No| O["Wait & Check Again"]
    
    N --> P["Start FFmpeg Recording"]
    P --> Q["Save to downloads/<br/>Platform/Streamer"]
    
    Q --> R["Monitor Recording"]
    R --> S{"Stream Still Live?"}
    S -->|Yes| R
    S -->|No| T["Stop Recording"]
    
    T --> U["Post-process Video<br/>(Convert to MP4)"]
    U --> V["Send Notifications<br/>(WeChat, DingTalk, Email)"]
    
    O --> W["Sleep for Loop Time"]
    V --> W
    W --> G
    
    style A fill:#e1f5fe
    style P fill:#c8e6c9
    style J fill:#fff3e0
    style K fill:#fce4ec
    style V fill:#f3e5f5
```

---

Based on my analysis of the DouyinLiveRecorder project, here's how this project works:

## **DouyinLiveRecorder - Multi-Platform Live Stream Recording Tool**

### **üéØ Main Purpose**
This is a comprehensive live stream recording tool that can automatically monitor and record live streams from **50+ platforms** including Douyin (TikTok China), TikTok, Kuaishou, Huya, Douyu, Bilibili, YouTube, and many more.

### **üèóÔ∏è Core Architecture**

The project follows a modular architecture:

1. **Main Controller** (`main.py`) - Orchestrates the entire recording process
2. **Spider Module** (`src/spider.py`) - Extracts live stream data from different platforms
3. **Stream Module** (`src/stream.py`) - Gets actual streaming URLs
4. **Room Module** (`src/room.py`) - Handles room/channel identification
5. **JavaScript Engine** (`src/javascript/`) - Platform-specific decryption algorithms
6. **Message Push** (`msg_push.py`) - Sends notifications when streams start/stop

### **üîÑ How It Works**

1. **Configuration**: Users add live room URLs to `config/URL_config.ini` and configure settings in `config/config.ini`

2. **Monitoring Loop**: The tool continuously monitors all configured URLs at set intervals (default 300 seconds)

3. **Platform Detection**: For each URL, it identifies the platform and uses the appropriate extraction method

4. **Stream Extraction**: 
   - Uses platform-specific APIs and JavaScript algorithms to decrypt stream URLs
   - Handles anti-bot measures and authentication cookies
   - Supports different video qualities (ÂéüÁîª/Ë∂ÖÊ∏Ö/È´òÊ∏Ö/Ê†áÊ∏Ö)

5. **Recording Process**:
   - Uses **FFmpeg** to record the live stream
   - Supports multiple formats (TS, MP4, FLV, MKV)
   - Implements segmented recording to prevent file corruption
   - Organizes files by platform and streamer

6. **Post-Processing**:
   - Converts recordings to MP4 format
   - Can force H.264 encoding for compatibility
   - Generates subtitle files with timestamps

7. **Notifications**: Sends real-time alerts via WeChat, DingTalk, Telegram, Email when streams start/stop

### **üåü Key Features**

- **Multi-Platform Support**: 50+ platforms including Chinese and international sites
- **Quality Selection**: Supports different video qualities per stream
- **Proxy Support**: Built-in proxy support for overseas platforms
- **Docker Support**: Can run in containers
- **Robust Error Handling**: Continues monitoring even if individual streams fail
- **Flexible Configuration**: Extensive customization options
- **Live Notifications**: Real-time status updates
- **Anti-Detection**: Uses JavaScript engines to bypass platform protections

### **üõ†Ô∏è Technical Stack**

- **Python 3.10+** with asyncio for concurrent processing
- **FFmpeg** for video recording
- **JavaScript (ExecJS)** for platform-specific algorithms
- **HTTP/HTTPX** for web requests with HTTP/2 support
- **Configparser** for configuration management
- **Docker** for containerized deployment

### **üìÅ File Organization**

```
downloads/
‚îú‚îÄ‚îÄ douyin/
‚îÇ   ‚îî‚îÄ‚îÄ streamer_name/
‚îÇ       ‚îî‚îÄ‚îÄ 2024-01-01_20-30-00_stream_title.ts
‚îú‚îÄ‚îÄ bilibili/
‚îú‚îÄ‚îÄ youtube/
‚îî‚îÄ‚îÄ ...
```

This tool essentially acts as an automated "screen recorder" for live streams, but instead of capturing your screen, it directly downloads the video streams from the platforms' servers, making it much more efficient and higher quality than traditional screen recording methods.

---

_**User**_

write the analyzer and discover how this project work with a visual diagram to a markdown file in docs folder

---

_**Assistant**_

I'll create a comprehensive analysis document with visual diagrams explaining how the DouyinLiveRecorder project works. Let me first create the docs folder and then write a detailed markdown file.

---

## Todo List

- [-] Create docs folder structure
- [ ] Analyze project architecture and components
- [ ] Create visual diagrams for workflow and architecture
- [ ] Write comprehensive markdown analysis document
- [ ] Document platform-specific implementations

---

<details>
            <summary>Listed directory undefined ‚Ä¢ **0** results</summary>
        
No results found
</details>

---

```bash
mkdir -p /Users/truong.nguyen3/Documents/_work_samples/DouyinLiveRecorder/docs
```

```
CL-LT-FV5217G4MK:DouyinLiveRecorder truong.nguyen3$ mkdir -p /Users/truong.nguyen3/Documents/_work_sample
CL-LT-FV5217G4MK:DouyinLiveRecorder truong.nguyen3$ mkdir -p /Users/truong.nguyen3/Documents/_work_sample
s/DouyinLiveRecorder/docs
CL-LT-FV5217G4MK:DouyinLiveRecorder truong.nguyen3$
```

---



---

_**User**_

continue

---

_**Assistant**_

## Todo List

- [x] Create docs folder structure
- [ ] Analyze project architecture and components
- [ ] Create visual diagrams for workflow and architecture
- [ ] Write comprehensive markdown analysis document
- [ ] Document platform-specific implementations

---



---

Read file: undefined

---

Read file: undefined

---

## Todo List

- [x] Create docs folder structure
- [-] Analyze project architecture and components
- [ ] Create visual diagrams for workflow and architecture
- [ ] Write comprehensive markdown analysis document
- [ ] Document platform-specific implementations

---



---

Read file: undefined

---

Read file: undefined

---

Now let me create a comprehensive analysis document with visual diagrams:

---

## Todo List

- [x] Create docs folder structure
- [x] Analyze project architecture and components
- [ ] Create visual diagrams for workflow and architecture
- [-] Write comprehensive markdown analysis document
- [ ] Document platform-specific implementations

---



---

Now let me create additional diagrams to complement the analysis and complete the documentation:

---

## Todo List

- [x] Create docs folder structure
- [x] Analyze project architecture and components
- [-] Create visual diagrams for workflow and architecture
- [x] Write comprehensive markdown analysis document
- [ ] Document platform-specific implementations

---



---

Now let me create a final document that covers platform-specific implementations:

---

## Todo List

- [x] Create docs folder structure
- [x] Analyze project architecture and components
- [x] Create visual diagrams for workflow and architecture
- [x] Write comprehensive markdown analysis document
- [-] Document platform-specific implementations

---



---

Finally, let me create an index file to tie all the documentation together and check for any linting issues:

---

## Todo List

- [x] Create docs folder structure
- [x] Analyze project architecture and components
- [x] Create visual diagrams for workflow and architecture
- [x] Write comprehensive markdown analysis document
- [x] Document platform-specific implementations

---



---



---

Perfect! Let me verify the final structure of our documentation:

---

<details>
            <summary>Listed directory undefined ‚Ä¢ **0** results</summary>
        
No results found
</details>

---

```bash
ls -la docs/
```

```
CL-LT-FV5217G4MK:DouyinLiveRecorder truong.nguyen3$ ls -la docs/
total 112
drwxr-xr-x@  6 truong.nguyen3  NITECO\Domain Users    192 Aug  7 16:50 .
drwxr-xr-x@ 24 truong.nguyen3  NITECO\Domain Users    768 Aug  7 16:44 ..
-rw-r--r--@  1 truong.nguyen3  NITECO\Domain Users   5644 Aug  7 16:50 README.md
-rw-r--r--@  1 truong.nguyen3  NITECO\Domain Users  13643 Aug  7 16:48 architecture-diagrams.md
-rw-r--r--@  1 truong.nguyen3  NITECO\Domain Users  13731 Aug  7 16:49 platform-implementations.md
-rw-r--r--@  1 truong.nguyen3  NITECO\Domain Users  15335 Aug  7 16:47 project-analysis.md
CL-LT-FV5217G4MK:DouyinLiveRecorder truong.nguyen3$
```

---

Perfect! I have successfully completed the comprehensive analysis and documentation of the DouyinLiveRecorder project. Here's a summary of what I've created:

## üìã Documentation Suite Created

I've created a comprehensive documentation suite in the `docs/` folder with 4 detailed documents:

### 1. **`README.md`** (5.6KB) - Documentation Index
- Overview of the entire documentation suite
- Quick start guide for different user types
- Summary of key features and architecture
- Navigation guide to other documents

### 2. **`project-analysis.md`** (15.3KB) - Main Technical Analysis
- Complete project overview and purpose
- Detailed architecture breakdown with visual diagrams
- Core components analysis (Main Controller, Spider Module, Stream Module, etc.)
- Workflow analysis with sequence diagrams
- Platform support matrix (50+ platforms)
- Technical implementation details
- Configuration system breakdown
- Error handling and monitoring strategies
- Installation and dependencies

### 3. **`architecture-diagrams.md`** (13.6KB) - Visual Architecture
- System architecture overview diagram
- Recording workflow sequence diagram
- Spider module class diagram
- Data flow architecture
- Component interaction diagrams
- Error handling state diagram
- Performance monitoring dashboard
- Development architecture

### 4. **`platform-implementations.md`** (13.7KB) - Platform-Specific Details
- Detailed implementation for major platforms (Douyin, TikTok, Bilibili, YouTube)
- Platform categorization (Chinese, International, Regional)
- Anti-detection strategies and solutions
- Platform-specific challenges and solutions
- Proxy strategy by platform
- Performance comparison matrix
- Future platform roadmap

## üéØ Key Insights Discovered

Through my analysis, I discovered that DouyinLiveRecorder is:

1. **Sophisticated Multi-Platform Tool**: Supports 50+ live streaming platforms with platform-specific implementations
2. **Advanced Anti-Detection System**: Uses JavaScript engines to bypass platform protection mechanisms
3. **Robust Architecture**: Modular design with error recovery, proxy support, and concurrent processing
4. **User-Friendly**: Easy configuration through INI files and automated recording workflows
5. **Production-Ready**: Docker support, comprehensive logging, and notification systems

## üìä Visual Diagrams Included

The documentation includes 15+ Mermaid diagrams covering:
- System architecture overview
- Recording workflow processes
- Component interactions
- Data flow diagrams
- Error handling flows
- Platform implementation strategies
- Performance monitoring dashboards

## üîß Technical Details Covered

- **Core Components**: Main controller, spider modules, stream processors
- **Platform Support**: Detailed analysis of Chinese (Douyin, Bilibili) and International (TikTok, YouTube) platforms
- **Anti-Detection**: JavaScript-based signature generation and cookie management
- **Error Handling**: Comprehensive retry mechanisms and graceful degradation
- **Performance**: Success rates, response times, and scalability metrics

All documentation is now available in the `docs/` folder and provides a complete understanding of how this sophisticated live stream recording project works!

---

_**User**_

which func to download video when hls link received and each ffmpeg process?

---

_**Assistant**_

Let me analyze the FFmpeg recording process and how HLS links are handled for video downloading.

---



---



---

Now let me get the specific functions that handle HLS streams and FFmpeg command construction:

---

Read file: undefined

---

Read file: undefined

---

Let me also look at how the real_url (HLS link) is determined and used:

---



---

Read file: undefined

---

Now let me look at how the stream URL selection works:

---



---

Read file: undefined

---

Based on my analysis of the code, here's how DouyinLiveRecorder handles HLS link downloads and FFmpeg processes:

## üéØ Key Functions for HLS Video Download

### 1. **`start_record()` Function** - Main Recording Orchestrator
**Location**: `main.py:479`

This is the primary function that handles the entire recording workflow:

```python
def start_record(url_data: tuple, count_variable: int = -1) -> None:
    # Main loop that:
    # 1. Gets stream data from spider modules
    # 2. Extracts HLS/FLV URLs 
    # 3. Constructs FFmpeg commands
    # 4. Starts recording processes
```

### 2. **Stream URL Selection Logic** - `main.py:1046`

```python
# Gets the actual streaming URL (HLS/FLV)
real_url = port_info.get('record_url')

# Platform-specific URL handling
if enable_https_recording and real_url.startswith("http://"):
    real_url = real_url.replace("http://", "https://")
```

### 3. **FFmpeg Command Construction** - `main.py:1104-1124`

The core FFmpeg command for HLS downloading:

```python
ffmpeg_command = [
    'ffmpeg', "-y",
    "-v", "verbose",
    "-rw_timeout", rw_timeout,           # Read/write timeout
    "-loglevel", "error",
    "-hide_banner",
    "-user_agent", user_agent,
    "-protocol_whitelist", "rtmp,crypto,file,http,https,tcp,tls,udp,rtp,httpproxy",
    "-thread_queue_size", "1024",
    "-analyzeduration", analyzeduration,  # How long to analyze input
    "-probesize", probesize,             # How much data to probe
    "-fflags", "+discardcorrupt",        # Discard corrupted packets
    "-re", "-i", real_url,               # Input HLS URL
    "-bufsize", bufsize,                 # Buffer size
    "-sn", "-dn",                        # Skip subtitles and data streams
    "-reconnect_delay_max", "60",        # Max reconnection delay
    "-reconnect_streamed", "-reconnect_at_eof",  # Reconnection options
    "-max_muxing_queue_size", max_muxing_queue_size,
    "-correct_ts_overflow", "1",         # Handle timestamp overflow
    "-avoid_negative_ts", "1"            # Avoid negative timestamps
]
```

### 4. **Process Execution** - `check_subprocess()` Function

**Location**: `main.py:385-434`

```python
def check_subprocess(record_name: str, record_url: str, ffmpeg_command: list, 
                     save_type: str, script_command: str | None = None) -> bool:
    save_file_path = ffmpeg_command[-1]
    
    # Start FFmpeg process
    process = subprocess.Popen(
        ffmpeg_command, 
        stdin=subprocess.PIPE, 
        stderr=subprocess.STDOUT, 
        startupinfo=get_startup_info(os_type)
    )
    
    # Monitor the process
    while process.poll() is None:
        if record_url in url_comments or exit_recording:
            # Graceful shutdown if recording is stopped
            if os.name == 'nt':
                process.stdin.write(b'q')  # Send quit command
                process.stdin.close()
            else:
                process.send_signal(signal.SIGINT)
            process.wait()
            return True
        time.sleep(1)
```

## üîÑ HLS Processing Workflow

```mermaid
sequenceDiagram
    participant Spider as Spider Module
    participant Stream as Stream Processor  
    participant Main as Main Controller
    participant FFmpeg as FFmpeg Process
    
    Spider->>Stream: Extract stream data
    Stream->>Stream: Select quality & format
    Stream->>Main: Return stream URLs
    
    Main->>Main: Choose HLS vs FLV
    Note over Main: real_url = port_info.get('record_url')
    
    Main->>Main: Build FFmpeg command
    Note over Main: Add HLS-specific parameters
    
    Main->>FFmpeg: Start subprocess.Popen()
    FFmpeg->>FFmpeg: Download HLS segments
    FFmpeg->>Main: Write to output file
    
    loop Monitor Process
        Main->>FFmpeg: Check process status
        alt Process Running
            FFmpeg->>Main: Continue recording
        else Process Ended/Stopped
            Main->>Main: Cleanup & post-process
        end
    end
```

## üìä Platform-Specific URL Handling

### HLS URL Selection by Platform:

| Platform | URL Type | Key Function | Special Handling |
|----------|----------|--------------|------------------|
| **Douyin** | HLS/FLV | `get_douyin_stream_url()` | X-Bogus signature |
| **TikTok** | HLS | `get_tiktok_stream_url()` | Geo-blocking bypass |
| **Bilibili** | HLS/FLV | `get_bilibili_stream_url()` | Quality authentication |
| **YouTube** | HLS | `get_youtube_stream_url()` | Manifest parsing |
| **Custom** | HLS/FLV | Direct URL | `record_url` direct assignment |

### URL Processing Examples:

```python
# Douyin/TikTok - Stream module extracts both formats
result = {
    'm3u8_url': m3u8_url,      # HLS format
    'flv_url': flv_url,        # FLV format  
    'record_url': m3u8_url or flv_url  # Preferred URL
}

# Custom streams - Direct assignment
if record_url.find(".m3u8") > -1:
    port_info['m3u8_url'] = record_url
elif record_url.find(".flv") > -1:
    port_info['flv_url'] = record_url
```

## ‚öôÔ∏è FFmpeg Process Parameters for HLS

### Key HLS-Specific Parameters:

- **`-protocol_whitelist`**: Allows HTTP/HTTPS protocols for HLS
- **`-reconnect_streamed`**: Enables reconnection for live streams
- **`-reconnect_at_eof`**: Reconnects when stream ends
- **`-analyzeduration`**: Time to analyze stream structure
- **`-probesize`**: Amount of data to probe for stream info
- **`-fflags +discardcorrupt`**: Handles corrupted HLS segments

### Platform-Specific Headers:

```python
record_headers = {
    'PandaTV': 'origin:https://www.pandalive.co.kr',
    'WinkTV': 'origin:https://www.winktv.co.kr', 
    'shopee': f'origin:{live_domain}',
    'ÂçÉÂ∫¶ÁÉ≠Êí≠': 'referer:https://qiandurebo.com'
}
```

## üìÅ Output File Handling

The system supports multiple output formats:
- **TS** (Transport Stream) - Default for HLS
- **FLV** - Flash Video format
- **MP4** - Post-processing conversion
- **Audio only** - MP3/M4A for audio streams

Each FFmpeg process writes directly to the final output file, with optional post-processing for format conversion.

---

_**User**_

so python process does not has been blocked if ffmpeg running? how many records this project can do at the same time? which spec requirements needed for a vps to handle 100 records at the same time with this project?

---

_**Assistant**_

Excellent questions! Let me analyze the concurrency model and resource requirements for this project.

---



---



---

Now let me check the configuration values and see how threading and process management work:

---



---

Read file: undefined

---

Let me check the default values and analyze resource usage patterns:

---



---

Read file: undefined

---

Perfect! Now I have a comprehensive understanding of the concurrency model. Let me analyze this:

## üöÄ **Concurrency Model Analysis**

### **Python Process is NOT Blocked by FFmpeg**

**Answer: NO, the Python process is NOT blocked when FFmpeg is running.**

Here's how the concurrency works:

### üîß **Threading Architecture**

```python
# Each stream gets its own thread
create_var[f'thread_{monitoring}'] = threading.Thread(target=start_record, args=args)
create_var[f'thread_{monitoring}'].daemon = True
create_var[f'thread_{monitoring}'].start()

# FFmpeg runs as subprocess (non-blocking)
process = subprocess.Popen(
    ffmpeg_command, 
    stdin=subprocess.PIPE, 
    stderr=subprocess.STDOUT
)

# Python monitors the process without blocking
while process.poll() is None:
    # Check if recording should stop
    time.sleep(1)  # Only sleeps 1 second at a time
```

### üìä **Concurrent Recording Limits**

The project can handle multiple simultaneous recordings based on:

#### **1. Network Thread Limit (Configurable)**
```python
max_request = int(read_config_value(config, 'ÂΩïÂà∂ËÆæÁΩÆ', 'Âêå‰∏ÄÊó∂Èó¥ËÆøÈóÆÁΩëÁªúÁöÑÁ∫øÁ®ãÊï∞', 3))
semaphore = threading.Semaphore(max_request)

# Default: 3 concurrent network requests
# Each platform API call uses: with semaphore:
```

#### **2. Dynamic Network Thread Adjustment**
```python
def adjust_max_request():
    # Automatically adjusts based on error rate
    if error_rate > error_threshold:
        max_request = max(1, max_request - 1)  # Reduce on errors
    elif error_rate < error_threshold / 2:
        max_request += 1  # Increase when stable
```

#### **3. Unlimited Recording Processes**
- **No limit on simultaneous FFmpeg processes**
- Each recording runs in its own subprocess
- Limited only by system resources

## üéØ **Actual Concurrent Recording Capacity**

Based on the code analysis:

| Component | Limit | Type |
|-----------|-------|------|
| **Network API Calls** | 3 (default, configurable) | Semaphore-controlled |
| **Active Recordings** | Unlimited | Process-based |
| **Monitoring Threads** | Unlimited | Thread-based |

## üíª **VPS Specifications for 100 Concurrent Recordings**

### **Resource Calculation per Recording**

#### **Memory Usage per Stream:**
```python
# FFmpeg Buffer Settings
bufsize = "8000k"                    # 8MB per domestic stream  
bufsize = "15000k"                   # 15MB per overseas stream
analyzeduration = "20000000"         # 20MB analysis buffer
probesize = "10000000"               # 10MB probe buffer
max_muxing_queue_size = "1024"       # Additional queue memory
```

**Estimated per stream:**
- **Domestic streams**: ~50-80MB per recording
- **Overseas streams**: ~80-120MB per recording
- **Python overhead**: ~10-20MB per thread

#### **CPU Usage per Stream:**
- **FFmpeg process**: 0.1-0.5 CPU cores per 1080p stream
- **Python monitoring**: Minimal (~0.01 cores per thread)

#### **Network Bandwidth:**
- **1080p stream**: 2-8 Mbps
- **720p stream**: 1-3 Mbps  
- **480p stream**: 0.5-1.5 Mbps

### **Recommended VPS Specifications for 100 Recordings**

#### **üî• Minimum Specifications:**
```yaml
CPU: 16+ cores (32+ vCPUs)
RAM: 32GB DDR4
Storage: 1TB NVMe SSD (for recordings)
Network: 1Gbps unmetered
OS: Ubuntu 20.04+ / CentOS 8+
```

#### **üöÄ Recommended Specifications:**
```yaml
CPU: 24+ cores (48+ vCPUs) 
RAM: 64GB DDR4
Storage: 2TB NVMe SSD RAID
Network: 2.5Gbps+ unmetered
OS: Ubuntu 22.04 LTS
```

#### **‚ö° Optimal Specifications:**
```yaml
CPU: 32+ cores (64+ vCPUs)
RAM: 128GB DDR4
Storage: 4TB NVMe SSD RAID 10
Network: 10Gbps unmetered
OS: Ubuntu 22.04 LTS
```

### **Detailed Resource Breakdown (100 streams)**

| Resource | Minimum | Recommended | Optimal |
|----------|---------|-------------|---------|
| **CPU Cores** | 16 | 24 | 32 |
| **RAM** | 32GB | 64GB | 128GB |
| **Storage/Hour** | 50GB | 100GB | 200GB |
| **Network** | 500Mbps | 1Gbps | 2.5Gbps |
| **FFmpeg Processes** | 100 | 100 | 100 |
| **Python Threads** | ~110 | ~110 | ~110 |

### **Performance Optimizations for 100+ Streams**

#### **1. Configuration Tuning:**
```ini
# config.ini optimizations
Âêå‰∏ÄÊó∂Èó¥ËÆøÈóÆÁΩëÁªúÁöÑÁ∫øÁ®ãÊï∞ = 10        # Increase API concurrency
Âæ™ÁéØÊó∂Èó¥(Áßí) = 600                   # Reduce API polling frequency  
ËßÜÈ¢ë‰øùÂ≠òÊ†ºÂºè = ts                    # Use TS format (more efficient)
ÂàÜÊÆµÂΩïÂà∂ÊòØÂê¶ÂºÄÂêØ = ÊòØ                # Enable segmented recording
ÂΩïÂà∂Á©∫Èó¥Ââ©‰ΩôÈòàÂÄº(gb) = 50           # Monitor disk space
```

#### **2. System Optimizations:**
```bash
# Increase file descriptors
echo "* soft nofile 65535" >> /etc/security/limits.conf
echo "* hard nofile 65535" >> /etc/security/limits.conf

# Optimize network settings
echo 'net.core.rmem_max = 134217728' >> /etc/sysctl.conf
echo 'net.core.wmem_max = 134217728' >> /etc/sysctl.conf
echo 'net.ipv4.tcp_rmem = 4096 87380 134217728' >> /etc/sysctl.conf

# Increase max processes
echo 'kernel.pid_max = 131072' >> /etc/sysctl.conf
```

#### **3. FFmpeg Optimizations:**
```python
# Lower quality for mass recording
bufsize = "4000k"                    # Reduce buffer size
analyzeduration = "10000000"         # Faster analysis
probesize = "5000000"               # Smaller probe
```

## üìà **Scaling Strategy**

### **Horizontal Scaling (Multiple VPS)**
- **50 streams per VPS** (recommended)
- **Load balance by geographic regions**
- **Separate domestic vs international platforms**

### **Monitoring Requirements**
- **Disk space monitoring** (recordings grow quickly)
- **CPU/Memory monitoring** (prevent OOM kills)
- **Network monitoring** (bandwidth saturation)
- **Process monitoring** (FFmpeg process health)

## ‚ö†Ô∏è **Important Considerations**

### **1. Network Bandwidth Planning**
- **100 x 1080p streams ‚âà 2-8 Gbps**
- **Account for upload bandwidth if backing up**
- **Consider CDN/proxy costs for international streams**

### **2. Storage Planning**
- **1080p stream ‚âà 500MB-1GB per hour**
- **100 streams ‚âà 50-100GB per hour**
- **Plan for 3-7 days retention minimum**

### **3. Legal Compliance**
- **Ensure compliance with platform ToS**
- **Consider geographical restrictions**
- **Plan for DMCA/takedown procedures**

The project architecture is well-designed for massive concurrent recording, with the main bottleneck being system resources rather than software limitations.

---

_**User**_

write down the latest research to docs folder

---

_**Assistant**_

I'll create a comprehensive research document based on our latest analysis of the concurrency model and resource requirements for the DouyinLiveRecorder project.

---



---



---

